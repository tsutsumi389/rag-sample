# RAG CLI Application - Environment Configuration Sample
# Copy this file to .env and modify as needed

# Ollama Configuration
# ====================
# Base URL for Ollama API endpoint
OLLAMA_BASE_URL=http://localhost:11434

# Model for text generation (LLM)
# Available models: gpt-oss, llama3.2, llama2, mistral, etc.
# Run 'ollama list' to see installed models
OLLAMA_LLM_MODEL=gpt-oss

# Model for generating embeddings
# Recommended: nomic-embed-text (lightweight and efficient)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ChromaDB Configuration
# ======================
# Directory path for ChromaDB persistent storage
# Can be absolute or relative path
CHROMA_PERSIST_DIRECTORY=./chroma_db

# Document Processing Configuration
# ==================================
# Size of text chunks (in characters)
# Range: 100-10000, recommended: 500-2000
CHUNK_SIZE=1000

# Overlap between consecutive chunks (in characters)
# Must be less than CHUNK_SIZE
# Higher overlap = better context continuity, but more storage
CHUNK_OVERLAP=200

# Logging Configuration
# =====================
# Log level for application output
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
